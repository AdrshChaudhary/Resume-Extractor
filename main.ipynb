{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resume Detail Extracting tool\n",
    "### This tool extracts the import the details from multiple resumes at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Phone numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_phone(text):\n",
    "    \"\"\"Extract phone numbers with improved pattern matching.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"Not Found\"\n",
    "    \n",
    "    # Match various phone number formats\n",
    "    patterns = [\n",
    "        r\"\\+91[-\\s]?\\d{10}\",  # +91 followed by 10 digits\n",
    "        r\"\\b\\d{10}\\b\",        # Plain 10 digits\n",
    "        r\"\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4}\"  # XXX-XXX-XXXX format\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        if matches:\n",
    "            # Clean the found phone number\n",
    "            phone = re.sub(r'[^\\d+]', '', matches[0])\n",
    "            return phone\n",
    "    \n",
    "    return \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract LinkedIN URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_linkedin(text):\n",
    "    \"\"\"Extract LinkedIn URLs with improved pattern matching.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"Not Found\"\n",
    "    \n",
    "    # First, look for lines containing \"linkedin\" and extract URLs\n",
    "    lines = text.lower().split('\\n')\n",
    "    for line in lines:\n",
    "        if 'linkedin' in line:\n",
    "            # Try to extract URL from the line\n",
    "            url_match = re.search(r'(?:https?:\\/\\/)?(?:www\\.)?linkedin\\.com\\/in\\/[a-zA-Z0-9\\-_.]+\\/?', line)\n",
    "            if url_match:\n",
    "                return url_match.group()\n",
    "            \n",
    "            # If no URL format found, look for profile identifier after \"linkedin.com/in/\"\n",
    "            profile_match = re.search(r'linkedin\\.com\\/in\\/([a-zA-Z0-9\\-_.]+)', line)\n",
    "            if profile_match:\n",
    "                return f\"linkedin.com/in/{profile_match.group(1)}\"\n",
    "    \n",
    "    # Fallback: look for LinkedIn URL anywhere in text\n",
    "    url_match = re.search(r'(?:https?:\\/\\/)?(?:www\\.)?linkedin\\.com\\/in\\/[a-zA-Z0-9\\-_.]+\\/?', text.lower())\n",
    "    return url_match.group() if url_match else \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Email Addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_email(text):\n",
    "    \"\"\"Extract email addresses with improved pattern matching.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"Not Found\"\n",
    "    \n",
    "    # Look for email patterns\n",
    "    email_pattern = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b'\n",
    "    matches = re.findall(email_pattern, text)\n",
    "    \n",
    "    if matches:\n",
    "        # Return the first valid email found\n",
    "        return matches[0].lower()\n",
    "    \n",
    "    return \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_name(text):\n",
    "    \"\"\"Extract name from resume with improved logic.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"Not Found\"\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "    \n",
    "    # Skip empty lines and get the first non-empty line\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            # Remove common resume headers or titles\n",
    "            name = re.sub(r'\\b(resume|cv|curriculum vitae)\\b', '', line, flags=re.IGNORECASE).strip()\n",
    "            # Remove special characters and extra spaces\n",
    "            name = re.sub(r'[^\\w\\s]', '', name)\n",
    "            name = ' '.join(name.split())\n",
    "            if name:\n",
    "                return name\n",
    "    \n",
    "    return \"Not Found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract all the necessary details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resume_details(pdf_path):\n",
    "    \"\"\"Extract all relevant details from a PDF resume with improved extraction.\"\"\"\n",
    "    details = {\n",
    "        \"Name\": \"Not Found\",\n",
    "        \"Phone\": \"Not Found\",\n",
    "        \"Email\": \"Not Found\",\n",
    "        \"LinkedIn\": \"Not Found\",\n",
    "        \"Education\": \"Not Found\",\n",
    "        \"Work Experience\": \"Not Found\",\n",
    "        \"Skills\": \"Not Found\",\n",
    "        \"Certifications\": \"Not Found\",\n",
    "        \"File Name\": os.path.basename(pdf_path)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            text = \"\"\n",
    "            for page in pdf.pages:\n",
    "                extracted_text = page.extract_text()\n",
    "                if extracted_text:\n",
    "                    text += extracted_text + \"\\n\"\n",
    "            \n",
    "            if not text.strip():\n",
    "                print(f\"Warning: No text could be extracted from {pdf_path}\")\n",
    "                return details\n",
    "            \n",
    "            # Extract basic information\n",
    "            details[\"Name\"] = extract_name(text)\n",
    "            details[\"Phone\"] = extract_phone(text)\n",
    "            details[\"Email\"] = extract_email(text)\n",
    "            details[\"LinkedIn\"] = extract_linkedin(text)\n",
    "            \n",
    "            # Extract Education\n",
    "            education_sections = []\n",
    "            education_started = False\n",
    "            for line in text.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if re.search(r'\\b(education|qualification|academic|degree)\\b', line, re.IGNORECASE):\n",
    "                    education_started = True\n",
    "                    continue\n",
    "                if education_started and line:\n",
    "                    if re.search(r'\\b(experience|work|employment|skills|projects)\\b', line, re.IGNORECASE):\n",
    "                        education_started = False\n",
    "                        continue\n",
    "                    if any(keyword in line.lower() for keyword in ['university', 'college', 'institute', 'school', 'degree', 'b.tech', 'b.e', 'm.tech', 'diploma']):\n",
    "                        education_sections.append(line)\n",
    "            \n",
    "            details[\"Education\"] = '; '.join(education_sections) if education_sections else \"Not Found\"\n",
    "            \n",
    "            # Extract Work Experience\n",
    "            experience_sections = []\n",
    "            experience_started = False\n",
    "            for line in text.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if re.search(r'\\b(experience|work history|employment)\\b', line, re.IGNORECASE):\n",
    "                    experience_started = True\n",
    "                    continue\n",
    "                if experience_started and line:\n",
    "                    if re.search(r'\\b(education|skills|projects|certificates)\\b', line, re.IGNORECASE):\n",
    "                        experience_started = False\n",
    "                        continue\n",
    "                    if re.search(r'\\d{4}\\s*[-–]\\s*\\d{4}|\\d{4}\\s*[-–]\\s*present', line.lower()):\n",
    "                        experience_sections.append(line)\n",
    "            \n",
    "            details[\"Work Experience\"] = '; '.join(experience_sections) if experience_sections else \"Not Found\"\n",
    "            \n",
    "            # Extract Skills\n",
    "            skills_sections = []\n",
    "            skills_started = False\n",
    "            for line in text.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if re.search(r'\\b(technical skills|skills|technical expertise)\\b', line, re.IGNORECASE):\n",
    "                    skills_started = True\n",
    "                    continue\n",
    "                if skills_started and line:\n",
    "                    if re.search(r'\\b(experience|education|certificates|projects)\\b', line, re.IGNORECASE):\n",
    "                        skills_started = False\n",
    "                        continue\n",
    "                    if line and not re.match(r'^[\\W\\d]+$', line):  # Skip lines with only special characters or numbers\n",
    "                        skills_sections.append(line)\n",
    "            \n",
    "            details[\"Skills\"] = '; '.join(skills_sections) if skills_sections else \"Not Found\"\n",
    "            \n",
    "            # Extract Certifications\n",
    "            cert_sections = []\n",
    "            cert_started = False\n",
    "            for line in text.split('\\n'):\n",
    "                line = line.strip()\n",
    "                if re.search(r'\\b(certifications?|certificates?)\\b', line, re.IGNORECASE):\n",
    "                    cert_started = True\n",
    "                    continue\n",
    "                if cert_started and line:\n",
    "                    if re.search(r'\\b(education|experience|skills|projects)\\b', line, re.IGNORECASE):\n",
    "                        cert_started = False\n",
    "                        continue\n",
    "                    if re.search(r'\\b(certified|certification|certificate|udemy|coursera)\\b', line, re.IGNORECASE):\n",
    "                        cert_sections.append(line)\n",
    "            \n",
    "            details[\"Certifications\"] = '; '.join(cert_sections) if cert_sections else \"Not Found\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {pdf_path}: {e}\")\n",
    "    \n",
    "    return details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the extracted details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_text(text):\n",
    "    \"\"\"Clean text for Excel compatibility.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Replace problematic characters\n",
    "    text = text.replace('|', ';')\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text = text.replace('\\r', ' ')\n",
    "    \n",
    "    # Remove control characters\n",
    "    text = re.sub(r'[\\x00-\\x1f\\x7f-\\x9f]', '', text)\n",
    "    \n",
    "    # Replace multiple spaces with single space\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Limit text length for Excel\n",
    "    return text[:32767] if len(text) > 32767 else text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process all the PDFs in the input folder and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_resumes(folder_path, output_file):\n",
    "    all_details = []\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    \n",
    "    # Process each PDF file\n",
    "    pdf_files = [f for f in os.listdir(folder_path) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No PDF files found in {folder_path}\")\n",
    "        return\n",
    "    \n",
    "    for file_name in pdf_files:\n",
    "        pdf_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            print(f\"Processing: {file_name}\")\n",
    "            details = extract_resume_details(pdf_path)\n",
    "            sanitized_details = {k: sanitize_text(v) for k, v in details.items()}\n",
    "            all_details.append(sanitized_details)\n",
    "            print(f\"Successfully processed: {file_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {file_name}: {e}\")\n",
    "    \n",
    "    if not all_details:\n",
    "        print(\"No resumes were processed successfully.\")\n",
    "        return\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(all_details)\n",
    "    \n",
    "    # Save to Excel with error handling\n",
    "    try:\n",
    "        df.to_excel(output_file, index=False, engine='xlsxwriter')\n",
    "        print(f\"Successfully saved {len(df)} resume details to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        try:\n",
    "            df.to_excel(output_file, index=False, engine='openpyxl')\n",
    "            print(f\"Successfully saved {len(df)} resume details to: {output_file}\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Error saving to Excel. Attempting to save as CSV...\")\n",
    "            csv_output = output_file.rsplit('.', 1)[0] + '.csv'\n",
    "            df.to_csv(csv_output, index=False, encoding='utf-8-sig')\n",
    "            print(f\"Saved as CSV instead at: {csv_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run main by giving the directories location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    resumes_folder = \"E:/Data/Resume_gpt\"\n",
    "    output_excel = \"E:/Data/xl/resumes1_details.xlsx\"\n",
    "    \n",
    "    process_resumes(resumes_folder, output_excel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
